---
title: "Cyclistic - Cleaning & EDA"
output: html_notebook
---

This notebook documents the data cleaning and exploratory data analysis (EDA) process for the Cyclistic Project.

Analysed Period: July 1, 2022 - June 30, 2023  
Data Source: https://divvy-tripdata.s3.amazonaws.com/index.html 

To begin working with this process in the R notebook, please follow these steps:

1. Visit the provided link and download the trip data for the Analysed Period
2. Place the downloaded files in the 'cyclistic/data/raw' folder
3. Execute the script 'cyclistic/scripts/00_init_packages.R' to prepare the environment for analysis
4. Execute the script 'cyclistic/scripts/01_load_data.R' to combine & export raw data into a single dataset 

Once these preparatory steps are completed, you are ready to proceed with the project.

Disclaimer: In this analysis, some data is visualized using a log10 scale. It's important to note that while the log10 scale is effective for representing a wide range of values in a more compact and readable format, it can potentially distort the perception of the magnitude of differences between values. Therefore, caution should be exercised when interpreting relative sizes and differences in the data presented on this scale. It's designed to aid in identifying patterns and trends, particularly for data with large variances, but should not be used to draw direct quantitative comparisons.

### Section 1 - Data Preview

Import the combined raw data "trips_combined.csv":
```{r}
trips <- read_csv("../data/interim/trips_combined.csv")
```

Preview of the first few rows of the trips dataset:
```{r}
head(trips)
```

Obtain the count of NA values for each variable in the dataset:
```{r}
print(summarise_all(trips, ~sum(is.na(.))))
```

Determine if there are any duplicates by checking the `ride_id` column:
```{r}
print(any(duplicated(trips$ride_id)))
```


### Section 2 - Initial Cleaning from Data Preview

Extract "hour", "month", "weekday", and "trip duration" from from `started_at` and `ended_at`:
```{r}
trips <- trips %>% 
  mutate(
    hour = hour(started_at),
    weekday = wday(started_at, label = TRUE),
    month = month(started_at, label = TRUE),
    trip_duration = difftime(ended_at, started_at, units = "mins")
  )
```

Make selected character columns lower case: 
```{r}
trips <- trips %>% 
  mutate(across(c(rideable_type, start_station_name, end_station_name), tolower))
```

Trim white spaces in character columns:
```{r}
trips <- trips %>% mutate(across(where(is.character), trimws))
```

Make `rideable_type` and `member_casual` factors:
```{r}
trips$member_casual <- as.factor(trips$member_casual)
trips$rideable_type <- as.factor(trips$rideable_type)
```

Items need further investigation:  
1. Station related columns all have around 15% NAs, suggesting a pattern rather than random noise  
2. The consistency in the level of precision for coordinates related columns needs to be verified  
3. Handling NAs in `end_lat` and `end_lng`

### Section 3 - Variant Analysis
##### Rideable Types & Trip Duration
```{r, fig.width=8, fig.height=4}
trip_duration_distribution_plot <- ggplot(trips, aes(x = trip_duration)) +
  geom_histogram(aes(fill = rideable_type), bins = 50, alpha = 0.7) +
  facet_wrap(~rideable_type) +
  labs(title = "Distribution of Trip Duration by Rideable Type", x = "Trip Duration (mins)", y = "Count") +
  scale_y_continuous(labels = comma) +
  theme_minimal() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
    legend.position = "bottom", 
    )

trip_distribution_by_usertype_plot <- ggplot(trips, aes(x = rideable_type, fill = member_casual)) +
  geom_bar(position = "dodge") +
  labs(title = "Count of Rideable Types by User Type",
       x = "Rideable Type",
       y = "Count") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(hjust = 0.5),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
    legend.position = "bottom", 
    )

trip_duration_distribution_plot + trip_distribution_by_usertype_plot
```
We observed few anomalies from the graphs above that need further analysis:  
1. Docked bike counts are significantly lower compared to the other two rideable types  
2. All instances of docked type usage are associated with 'casual' user types  
3. The range of trip durations is abnormally broad, extending into negative values at the lower end  

We will perform a basic statistical analysis to find out the range of trip duration for each rideable types:
```{r}
trip_summary <- trips %>%
  group_by(rideable_type) %>%
  summarise(
    min_duration = min(trip_duration, na.rm = TRUE),
    max_duration = max(trip_duration, na.rm = TRUE),
    median_duration = median(trip_duration, na.rm = TRUE),
    average_duration = mean(trip_duration, na.rm = TRUE),
  )

# Printing results
print(trip_summary)
```
As shown in the table above, there are negative trip durations in the classic bike and electric bike, suggesting data inaccuracies, and docked bike shows abnormally long durations, skewing the overall data distribution.

Let's find out the percentage of negative duration trips exist in `classic_bike` and `eletric_bike`:
```{r}
neg_duration_rates <- trips %>%
  group_by(rideable_type) %>%
  summarise(rate = mean(trip_duration <= 0) * 100) %>%
  pivot_wider(names_from = rideable_type, values_from = rate)

print(glue("Negative duration in `classic_bike` trips: {neg_duration_rates$classic_bike}%
           Negative duration in `electric_bike` trips: {neg_duration_rates$electric_bike}%" ))
```

We will remove the negative duration trips in `classic_bike` and `electric_bike` from our dataset, as they represent an insignificant percentage. Additionally, trips shorter than 2 minutes will also be excluded, assuming these are false starts:
```{r}
trips$trip_duration <- as.numeric(trips$trip_duration)

trips <- trips %>% 
  filter_and_report(trip_duration > 2)
```

Next, we will re-examine "Trip Duration by Rideable Types", this time using a log10 scale to gain deeper insights into the previously observed anomalies:

```{r, fig.width=8, fig.height=4}
ggplot(trips, aes(x = trip_duration)) +
  geom_histogram(aes(fill = rideable_type), bins = 50, alpha = 0.7) +
  facet_wrap(~rideable_type) +
  labs(title = "Distribution of Trip Duration by Rideable Type", x = "Trip Duration (mins)", y = "Count (Log Scale)") +
  scale_y_continuous(trans = "log10", labels = comma) +
  theme_minimal() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
    legend.position = "bottom", 
  ) 
```
Extremely long durations, a significantly lower ride count, and exclusive usage by casual users are anomalies exclusively observed in docked bikes, collectively suggesting a pattern rather than random noise. Upon further investigation, we determined that docked bikes represent bikes taken out of circulation. Therefore, they will be excluded from our dataset for the purposes of this analysis.

Remove `docked_bike` trips from our analysis:
```{r}
trips <- trips %>% 
  filter_and_report(rideable_type != "docked_bike")
```
<br>

We will use the log10 scale once again to delve deeper into the trip durations distribution of classic and electric bikes, aiming to further refine our dataset: 
```{r, fig.width=8, fig.height=4}
ggplot(trips, aes(x = trip_duration)) +
  geom_histogram(bins = 50, alpha = 0.7, color = "black") +
  facet_wrap(~rideable_type, scales = "free") +
  labs(title = "Distribution of Classic and Electric Bike Trip Duration", 
       x = "Trip Duration (mins)", 
       y = "Count") +
  scale_y_continuous(trans = "log10", labels = comma) +
  theme_minimal() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
  )
```
In the classic bike graph, we observe a first-time directional change around the 531.25-minute mark, and around 350 minutes for electric bikes. Beyond these points, the majority of trips count fewer than 100, indicating a flattening trend. This may be due to bikes not being docked properly, leading to prolonged durations either from waiting to be docked correctly or being reused by other users. Additionally, a spike towards the end likely represents staff interventions for docking previously undocked bikes on a schedule. To better reflect typical user behavior, we will exclude trips exceeding these duration markers from our dataset. 

Although these longer trips constitute a small fraction of our data, their removal should enhance the accuracy in representing normal usage patterns:
```{r}
trips <- trips %>%
  filter_and_report(
    (rideable_type == "classic_bike" & trip_duration < 531.25) |
    (rideable_type == "electric_bike" & trip_duration < 350)
  )
```

Finally, let's visualize the trip duration distribution once again after it's been cleaned up: 
```{r, fig.width=8, fig.height=4}
ggplot(trips, aes(x = trip_duration)) +
  geom_histogram(aes(fill = rideable_type), bins = 50, alpha = 0.7) +
  facet_wrap(~rideable_type) +
  labs(title = "Distribution of Trip Duration by Rideable Type", x = "Trip Duration (mins)", y = "Count (Log Scale)") +
  scale_y_continuous(labels = comma) +
  theme_minimal() + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
    legend.position = "bottom", 
  )
```
Trip Duration Statisitcal Summary:
```{r}
trip_summary <- trips %>%
  group_by(rideable_type) %>%
  summarise(
    min_duration = min(trip_duration, na.rm = TRUE),
    max_duration = max(trip_duration, na.rm = TRUE),
    median_duration = median(trip_duration, na.rm = TRUE),
    average_duration = mean(trip_duration, na.rm = TRUE),
  )

# Printing results
print(trip_summary)
```


##### Exploring NAs

Let's get an update on NAs in our dataset:
```{r}
print(summarise_all(trips, ~sum(is.na(.))))
```

For how insignificant the amount is, we can simply remove rows with NAs in end coordinates: 
```{r}
trips <- trips %>% 
  filter_and_report(!is.na(end_lat) & !is.na(end_lng))
```

After further research, we learned that classic bikes dock exclusively at Divvy stations whereas electric bikes can dock at non-Divvy stations or public fixtures. This difference might explain the missing station ids and names in our data. 

Below, we will visualize records with any NA in station related columns: 
```{r, fig.width=8, fig.height=4}
missing_station <- trips %>% 
  filter(
    is.na(start_station_id) | 
    is.na(start_station_name) | 
    is.na(end_station_id) |
    is.na(end_station_name)
  )

ggplot(missing_station, aes(x = rideable_type)) +
  geom_bar(position = "dodge") +
  geom_text(
    aes(label = after_stat(count)), 
    stat = 'count', 
    position = position_dodge(width = 0.9), 
    vjust = -0.25
  ) +
  labs(
    title = "Records with Missing Station Info",
    x = "Rideable Type",
    y = "Count"
  ) +
  scale_y_continuous(labels = comma) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(hjust = 0.5),
    text = element_text(size = 7),  
    legend.key.size = unit(7, "pt"),  
    legend.position = "bottom"
  )
```
Our hypothesis is confirmed: the flexible return options for electric bikes are the primary cause of missing station IDs and names, leading to a predominance of electric bike records. Given that these NA values are anticipated in our analysis, we will retain the rows containing them. 

### Section 4 - Imputation
##### Station Ids and Station Names
For both start and end, station ids come in pairs with station name, thus their count should be the same. However, there is a very small difference between them in our data set.

We will use our imputation function to fix this. and print the missing value summary to see the difference:
```{r}
trips <- impute_from_pair(trips, "start_station_name", "start_station_id")
trips <- impute_from_pair(trips, "end_station_name", "end_station_id")
print(summarise_all(trips, ~sum(is.na(.))))
```
Now, for every station id, there is a station name. 

##### Impute Start & End Coordinates Precision Level
We can't improve the coordinate precision for those electric bike trips that either didn't start or end at a divvy station since there is no reference to a higher precision coordinates within our data. However, for trips that did start or end at a divvy bike station, through internal imputation, the accuracy can potentially be improved at scale. 

First, let's see how many divvy station actually has precise coordinates within our data. We will begin by adding  a column to label the precision in the form of decimal places, from 1 to 5, using our `add_and_impute_coord_precisions` function, and get a count of unique stations with a precision of 5 decimal point or more vs total unique station exist in our data set:
```{r}
trips <- add_and_impute_coord_precisions(trips, 5)

# Combine all stations instances and remove their start and end prefix
stations_combined <- combine_all_stations_instances(trips)

# Create a subset of all unique stations regardless of coordinate precision 
stations_unique <- distinct(stations_combined, station_name)

# Keep only the median value of 5 decimal places or higher coordinates
stations_precise <- stations_combined %>% 
  filter(coord_precision >= 5) %>% 
  group_by(station_name) %>% 
  summarise(med_lat = median(lat), med_lng = median(lng))

glue("Total unique stations: {nrow(stations_unique)} 
     Stations with precise coordinates: {nrow(stations_precise)}
     Stations without precise coordinates: {nrow(stations_unique) - nrow(stations_precise)}")
```

Before we move ahead with imputation, we must understand the potential impact and side effect of such operation. We will do so by investigating those stations that are without precise coordinates.  

Let's first see how many trips are associated with these stations:
```{r}
# Identify station without imprecise coordinates
stations_imprecise <- setdiff(
  stations_unique$station_name,
  stations_precise$station_name
)

# Subset the trips associated with these stations
trips_stations_imprecise <- trips %>%
  filter(
    start_station_name %in% stations_imprecise | 
     end_station_name %in% stations_imprecise
  )

glue("Trips associated with stations without precise coordinates: {nrow(trips_stations_imprecise)}")
```

The count is minimal, but we'll visualize these imprecise trips by rideable types to spot any patterns:  
```{r}
ggplot(trips_stations_imprecise, aes(x = rideable_type, fill = member_casual)) +
  geom_bar(position = "dodge") +
  geom_text(
    aes(label = ..count..), 
    stat = 'count', 
    position = position_dodge(width = 0.9), 
    vjust = -0.25
  ) +
  labs(title = "Count of Rideable Types by User Type",
       x = "Rideable Type",
       y = "Count") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(hjust = 0.5),
    text = element_text(size = 7), 
    legend.key.size = unit(7, "pt"),
    legend.position = "bottom", 
    )
```
As shown in the graph above, all but one are electric bike rides. After directly viewing these records, the only classic bike ride appears to have been returned to an incorrect station, given its end station name is "oh charging stx - test". This observation strengthens our findings, especially since many station names have the prefix "public rack". The higher count of casual users here might be due to their unfamiliarity with the locations of divvy stations. 

Considering that these records constitute only a small fraction of the total dataset, we are confident in moving forward with improving coordinate precision through internal imputation.

#### Improve Coodindates Precision Through Internal Imputation
In the below code chuck, the trips dataset undergoes a process to improve the precision of its station coordinates. The first step uses the `impute_coordinates` function, which enhances the precision of coordinates with less than five decimal points. This function works by aligning the trips dataset with a reference dataset, `stations_precise` from earlier, which contains station coordinates with a precision of five decimal points or higher. The next step utilizes `add_and_impute_coord_precisions` function once again to recalculate and update the precision of start and end point coordinates in trips: 
```{r}
# Let's keep a copy of the trips before imputation for comparison purpose
trip_before_imputation <- trips

# Imputate coordinates using station_precise when they precision are below 5 decimal point
trips <- impute_coordinates(trips, stations_precise, 5)

#Now let's re-impute the coordinate precision and compare before and after
trips <- add_and_impute_coord_precisions(trips, 5)

before_imputation <- count_lower_precision_coord(trip_before_imputation, 5)
after_imputation <- count_lower_precision_coord(trips, 5)

glue("count of improved coordinate precision:{before_imputation - after_imputation}")

# remove dataset for one time comparison 
rm(trip_before_imputation)
```


#### Add Trip Distance (dist_distance) Column to Dataset 

Next, we will use the `calculate_haversine_distance` function to compute the Haversine distance between the start and end coordinates. The resulting values will be stored in the `disp_distance` column:
```{r}
trips <- trips %>%
  mutate(
    disp_distance = calculate_haversine_distance(start_lat, start_lng, end_lat, end_lng),
  )

head(trips)
```










